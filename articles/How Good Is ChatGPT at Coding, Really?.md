from:: [x.com](https://x.com/Grady_Booch/status/1809824423475859469)
url:: [ChatGPT Code: Is the AI Actually Good At Writing Code? - IEEE Spectrum](https://spectrum.ieee.org/chatgpt-for-coding)
on:: 2024-07-07 16:57

The article is about a study from June 2024, [No Need to Lift a Finger Anymore? Assessing the Quality of Code Generation by ChatGPT](https://ieeexplore.ieee.org/document/10507163), evaluating the code generated by ChatGPT in terms of functionality, complexity, and security.

> Programmers have spent decades writing code for AI models, and now, in a full circle moment, AI is being used to write code.

On the first read, I thought "writing code for AI models" means "inadvertently participating in training of those models by having written publicly available code" :)

> ChatGPT has an extremely broad range of success when it comes to producing functional code—with a success rate ranging from anywhere as poor as 0.66 percent and as good as 89 percent

Matches my own impressions. Most of the time, it doesn't give me what I want, and I waste time trying to correct the result.

> his team sought to test GPT-3.5’s ability to address 728 coding problems from the LeetCode testing platform

Seriously, the study from June 2024 is about ChatGPT 3.5? With all my scepticism towards LLMs, this is not the best model to evaluate and prove a point, it's just too old, and modern ones definitely show better results.

> ability to produce functional code for “easy” coding problems dropped from 89 percent to 52 percent after 2021. And its ability to generate functional code for “hard” problems dropped from 40 percent to 0.66 percent

This is interesting. I wonder if GPT 4 is better in that regard.

> Interestingly, ChatGPT is able to generate code with smaller runtime and memory overheads than at least 50 percent of human solutions to the same LeetCode problems.

Not interesting at all. I don't think beating 50% runtime/memory on LeetCode is that hard.

> While ChatGPT was good at fixing compiling errors, it generally was not good at correcting its own mistakes.

Probably need to read the paper in full, I didn't quite understand what this means.